{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gzip: invalid option -- 'k'\n",
      "Try `gzip --help' for more information.\n",
      "mv: cannot stat ‘methylation_imputation/data/*.bed’: No such file or directory\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Error unpacking chromosomes data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-85bb868c71e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' mv methylation_imputation/data/*.bed data/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhave_chromosomes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Error unpacking chromosomes data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[0mencode_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'wgEncodeRegTfbsClusteredV3.bed'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Error unpacking chromosomes data"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, os.path\n",
    "from itertools import *\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import scipy.stats\n",
    "import sys\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "nproc = max(1, multiprocessing.cpu_count() - 1)\n",
    "\n",
    "# Warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Idempotent data retrieval script\n",
    "\n",
    "chromosomes = [1, 2, 6, 7, 11]\n",
    "def chromosome_files(n):\n",
    "    base = 'intersected_final_chr'\n",
    "    spec = '_cutoff_20_'\n",
    "    suffixes = ['train.bed', 'sample_partial.bed', 'sample_full.bed']\n",
    "    return [base + str(n) + spec + suffix for suffix in suffixes]\n",
    "all_chromosomes = set(chain.from_iterable(chromosome_files(n) for n in chromosomes))\n",
    "\n",
    "if 'methylation_imputation' not in [x for x in os.listdir('.') if os.path.isdir(x)]:\n",
    "    raise Exception('Missing assignment repository in cwd')\n",
    "\n",
    "if not os.path.exists('data'):\n",
    "    os.mkdir('data')\n",
    "\n",
    "def have_chromosomes(): return all_chromosomes.issubset(set(os.listdir('data')))\n",
    "if not have_chromosomes():\n",
    "    ! gunzip -k -f methylation_imputation/data/*.bed.gz\n",
    "    ! mv methylation_imputation/data/*.bed data/\n",
    "    if not have_chromosomes():\n",
    "        raise Exception('Error unpacking chromosomes data')\n",
    "\n",
    "encode_file = 'wgEncodeRegTfbsClusteredV3.bed'\n",
    "annotations_files = {encode_file}\n",
    "def have_annotations(): return annotations_files.issubset(set(os.listdir('data')))\n",
    "if not have_annotations():\n",
    "    ! gunzip -k -f methylation_imputation/annotations/*.bed.gz\n",
    "    ! mv methylation_imputation/annotations/*.bed data/\n",
    "    if not have_annotations():\n",
    "        raise Exception('Error unpacking ENCODE data')\n",
    "\n",
    "def read_tsv(name): return pd.read_csv(name, sep='\\t', header=None)\n",
    "train_chr1 = read_tsv('data/' + chromosome_files(1)[0])\n",
    "test_chr1_partial = read_tsv('data/' + chromosome_files(1)[1])\n",
    "test_chr1_full = read_tsv('data/' + chromosome_files(1)[2])\n",
    "\n",
    "unknown_chr1_ix = np.where((test_chr1_partial[5] == 0) & ~np.isnan(test_chr1_full[4]))[0]\n",
    "known_chr1_ix = np.where((test_chr1_partial[5] == 1) & ~np.isnan(test_chr1_partial[4]))[0]\n",
    "\n",
    "test_ix = unknown_chr1_ix\n",
    "train_ix = known_chr1_ix\n",
    "\n",
    "train_df = train_chr1\n",
    "train_tissues = ['b' + str(x) for x in range(train_chr1.shape[1] - 4)]\n",
    "train_df.columns = ['chromosome', 'start', 'end', 'strand'] + train_tissues\n",
    "\n",
    "test_df = test_chr1_full\n",
    "test_df.columns = ['chromosome', 'start', 'end', 'strand', 'filled', 'assayed']\n",
    "test_df['missing'] = test_chr1_partial[4]\n",
    "\n",
    "train_df['strand'] = train_df['strand'] == '+'\n",
    "test_df['strand'] = test_df['strand'] == '+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add CRE info\n",
    "rawe = read_tsv('data/' + encode_file)\n",
    "rawe.drop([4, 5, 6, 7], axis=1, inplace=True)\n",
    "rawe.columns = ['chromosome', 'start', 'end', 'tf']\n",
    "tfs = set(rawe['tf'])\n",
    "\n",
    "# This may take a minute\n",
    "from intervaltree import IntervalTree, Interval\n",
    "iv_chr1 = IntervalTree((Interval(*x[1]) for x in\n",
    "                       rawe[rawe['chromosome'] == 'chr1'][['start', 'end', 'tf']].iterrows()))\n",
    "def inside_tf(row):\n",
    "    overlap = [x.data for x in iv_chr1[row['start']:row['end']]]\n",
    "    return pd.Series({tf: (tf in overlap) for tf in tfs})\n",
    "# This may take 3 minutes\n",
    "train_df = train_df.merge(train_df[['start', 'end']].apply(inside_tf, axis=1), copy=False,\n",
    "                          left_index=True, right_index=True)\n",
    "\n",
    "import gc\n",
    "iv_chr1 = rawe = None\n",
    "gc.collect()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Double check that there actually are transcription factors in there:\n",
    "train_df[list(tfs)].sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Num train tissues', len(train_tissues))\n",
    "print('Num trans factors', len(tfs))\n",
    "train_df.loc[range(267, 273)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert len(train_df) == len(test_df)\n",
    "def count_unique(col):\n",
    "    return {x:sum(col == x) for x in set(col)}\n",
    "\n",
    "print('Chromosome 1')\n",
    "print('Total samples', len(train_df))\n",
    "print('Site lengths', count_unique(train_df['end'] - train_chr1['start']))\n",
    "print('Strand types', count_unique(train_df['strand']))\n",
    "print('Known (test) sample site counts', len(known_chr1_ix))\n",
    "print('Unknown (test) sample site counts', len(unknown_chr1_ix))\n",
    "print('NaN ratio in all train samples',\n",
    "      sum(sum(np.isnan(train_df[train_tissues].values))) / (len(train_df) * len(train_tissues)))\n",
    "print('NaN ratio in test', sum(np.isnan(test_df['missing'])) / len(test_df))\n",
    "assert sum(test_df['strand'] != train_df['strand']) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make sure our samples are pretty uniform from the genomic range\n",
    "def ticks(n): return np.arange(0.0, n) / n\n",
    "plt.plot(ticks(len(known_chr1_ix)), known_chr1_ix / len(train_df), '.')\n",
    "plt.plot([0, 1])\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.xlabel('CpG sample')\n",
    "plt.ylabel('entire chromosome')\n",
    "plt.title('QQ-plot of site positions')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "diffs = np.diff(known_chr1_ix)\n",
    "print('avg length between known sites', np.mean(diffs))\n",
    "print('sd of number of bp between sites', np.std(diffs))\n",
    "plt.plot(np.diff(known_chr1_ix))\n",
    "plt.xlabel('length between known sites')\n",
    "plt.ylabel('frequency')\n",
    "plt.title('histogram of adjacent site information')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Observe nearby site correlations\n",
    "def drop_nan_corr(x, y):\n",
    "    ix = np.where(~np.isnan(y) & ~np.isnan(x))\n",
    "    return scipy.stats.pearsonr(x[ix], y[ix])[0]\n",
    "# Choose a random site, check neighbors within vicinity of 'reach'\n",
    "reach = list(range(30))\n",
    "reach = [-x for x in reversed(reach)] + reach[1:]\n",
    "def sample_corr(reach):\n",
    "    site = random.randint(max(reach), len(train_chr1) - max(reach) - 1)\n",
    "    y = np.array(train_df.iloc[site][train_tissues[:-1]]\n",
    "                 .values).astype(np.float64)\n",
    "    nbrs = [site + i for i in reach]\n",
    "    xs = np.array(train_df.iloc[nbrs][train_tissues[:-1]]\n",
    "                  .values).astype(np.float64)\n",
    "    return np.array([drop_nan_corr(x, y) for x in xs])\n",
    "\n",
    "sample = 1000\n",
    "test = np.array([sample_corr(reach) for i in range(sample)])\n",
    "plt.errorbar(reach, np.mean(test, axis=0), fmt='-o', yerr=np.std(test, axis=0))\n",
    "plt.title('within tissue neighbor correlation (n={})'.format(sample))\n",
    "plt.ylabel('across tissue samples')\n",
    "plt.xlabel('site displacement')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Perhaps there are obvious sequence trends?\n",
    "def local_impute(data):\n",
    "    #http://stackoverflow.com/questions/9537543/replace-nans-in-numpy-array-with-closest-non-nan-value\n",
    "    mask = np.isnan(data)\n",
    "    data[mask] = np.interp(np.flatnonzero(mask), np.flatnonzero(~mask), data[~mask])\n",
    "    return data\n",
    "\n",
    "plt.figure(figsize=(10, 2))\n",
    "ratios = []\n",
    "plt.title('rolling mean (n = 1000) methylation levels in train tissues 0, 1, 33')\n",
    "plt.xlabel('genomic position')\n",
    "plt.ylabel('mean methyl. prop.')\n",
    "\n",
    "x = local_impute(np.copy(train_df['b0']))\n",
    "rolled = pd.Series(x).rolling(window=1000, win_type='boxcar').mean()\n",
    "ratios.append(np.std(x) / np.std(rolled))\n",
    "l0, = plt.plot(rolled, label='0')\n",
    "\n",
    "x = local_impute(np.copy(train_df['b1']))\n",
    "rolled = pd.Series(x).rolling(window=1000, win_type='boxcar').mean()\n",
    "ratios.append(np.std(x) / np.std(rolled))\n",
    "l1, = plt.plot(rolled, label='1')\n",
    "\n",
    "x = local_impute(np.copy(train_df['b33']))\n",
    "rolled = pd.Series(x).rolling(window=1000, win_type='boxcar').mean()\n",
    "ratios.append(np.std(x) / np.std(rolled))\n",
    "l33, = plt.plot(rolled, label='33')\n",
    "\n",
    "plt.legend(handles=[l0, l1, l33])\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()\n",
    "print('orig : rolling mean stddevs', ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sparsity\n",
    "print('Training tissue sparsities', [(train_df[i] <= 0.01).sum() / len(train_df) for i in train_tissues])\n",
    "print('Sample sparsity', (test_df['filled'][train_ix] <= 0.01).sum() / len(train_ix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Do mean imputation on our training data.\n",
    "def mean_impute(data):\n",
    "    mask = np.isnan(data)\n",
    "    data[mask] = float(data.mean()) # just = m messes with serialization\n",
    "    return data\n",
    "train_df_imp = train_df\n",
    "train_df_int = train_df\n",
    "for i in train_tissues:\n",
    "    train_df_imp[i] = mean_impute(train_df[i].copy())\n",
    "    train_df_int[i] = local_impute(train_df[i].copy())\n",
    "print('nans in mean-imputed', np.isnan(train_df_imp[train_tissues]).sum().sum())\n",
    "print('nans in interpolated', np.isnan(train_df_int[train_tissues]).sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr_mat = [[scipy.stats.pearsonr(train_df_imp\n",
    "                                  [a], train_df_imp[b])[0]\n",
    "             for a in train_tissues] for b in train_tissues]\n",
    "plt.imshow(corr_mat, interpolation='nearest', cmap=plt.cm.ocean)\n",
    "plt.title('chromosome correlation matrix')\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "def pandas_rmse(a, b):\n",
    "    # http://stackoverflow.com/questions/27783494/root-mean-square-error-of-two-pandas-series\n",
    "    return math.sqrt(a.sub(b).pow(2).mean())\n",
    "\n",
    "l = [pandas_rmse(train_df_imp[t].iloc[train_ix], test_df['filled'][train_ix]) for t in train_tissues]\n",
    "print('closest to test sample based on training data:', l.index(min(l)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We'll only test on the well-behaved chromosomes similar to our\n",
    "# test chromosome according to the cluster above, testable:\n",
    "testable_tissues = ['b' + str(i) for i in range(19, 25)]\n",
    "closest = 'b19'\n",
    "# this is just an eyeball selection, but should prove good enough to\n",
    "# offer decent generalization via cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define some evaluation functions\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def denanify(a, b):\n",
    "    mask = ~np.isnan(a) & ~np.isnan(b)\n",
    "    assert mask.sum() > 0\n",
    "    return a[mask], b[mask]\n",
    "\n",
    "def correct_half(a, b):\n",
    "    methylated_guess = a >= 0.5\n",
    "    methylated_exact = b >= 0.5\n",
    "    return (methylated_guess == methylated_exact).sum() / len(methylated_guess)\n",
    "\n",
    "# Function f should return its estimate for the value in 'test_tissue'\n",
    "# at each test_ix location. It gets its own copy of test_tissue, but\n",
    "# train_cols is shared.\n",
    "def eval_fold(f, train_cols, test_tissue, train_tissue_names):\n",
    "    nanned = test_tissue.copy()\n",
    "    nanned[test_ix] = np.nan\n",
    "    guess = f(train_cols, nanned, train_tissue_names)\n",
    "    assert sum(np.isnan(guess)) == 0\n",
    "    # test_ix doesn't have nans in the test_df['filled'] col, but\n",
    "    # within train_df there might be nans here.\n",
    "    exact = test_tissue[test_ix]\n",
    "    if not isinstance(guess, pd.Series):\n",
    "        guess = pd.Series(guess, index=exact.index)\n",
    "    assert len(guess) == len(exact)\n",
    "    guess, exact = denanify(guess, exact)\n",
    "    return np.array([pandas_rmse(guess, exact), correct_half(guess, exact),\n",
    "                     r2_score(exact, guess)])\n",
    "\n",
    "# Excludes the sparse chromosome from testing.\n",
    "def cv_folds(f, df=train_df, threading='multiprocessing',\n",
    "             additional_cols=[], test_tissues=testable_tissues):\n",
    "    rmse_acc = np.zeros(3)\n",
    "    ctr = 0\n",
    "    arguments = []\n",
    "    for t in test_tissues:\n",
    "        train_cols = train_tissues[:]\n",
    "        train_cols.remove(t)\n",
    "        arguments.append((f, df[train_cols + additional_cols], df[t], train_cols))\n",
    "    folds = [eval_fold(*i) for i in arguments] if not threading else \\\n",
    "            Parallel(n_jobs=nproc, backend=threading) \\\n",
    "                (delayed(eval_fold)(*i) for i in arguments)\n",
    "    return sum(folds) / len(folds)\n",
    "\n",
    "def perfstr(rmse_acc):\n",
    "    return 'rmse {} methylated acc {} R^2 {}'.format(*rmse_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# No trends.\n",
    "# Let's try imputing from but clearly we can impute from local neighbor data.\n",
    "# Try using no information for our test chromosome as a baseline.\n",
    "\n",
    "# Two simple approaches, with no information from other samples\n",
    "\n",
    "def interpolation(cols, partial, train_tissue_names):\n",
    "    return local_impute(partial).iloc[test_ix]\n",
    "print('interpolation', perfstr(cv_folds(interpolation)))\n",
    "\n",
    "def same_sample_mean(cols, partial, train_tissue_names):\n",
    "    return mean_impute(partial).iloc[test_ix]\n",
    "print('same tissue mean', perfstr(cv_folds(same_sample_mean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# As a dual approach, we can try using only information from the remaining tissues\n",
    "# For example, we might try to take a mean of methylation values along the same site\n",
    "def diff_sample_mean(cols, partial, train_tissue_names):\n",
    "    return cols[train_tissue_names].iloc[test_ix].mean(axis=1)\n",
    "print('diff tissue mean', perfstr(cv_folds(diff_sample_mean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nearest_neighbor(cols, partial, train_tissue_names):\n",
    "    nbr = min((pandas_rmse(cols[t].iloc[train_ix], partial.iloc[train_ix]), t)\n",
    "              for t in train_tissue_names)[1]\n",
    "    return cols[nbr].iloc[test_ix]\n",
    "print('1NN', perfstr(cv_folds(nearest_neighbor, df=train_df_imp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use the well-formedness of the other-tissue data to train a basic lm\n",
    "def sklearn_model(lm, cols, partial, train_tissue_names):\n",
    "    lm.fit(cols.iloc[train_ix], partial.iloc[train_ix])\n",
    "    return lm.predict(cols.iloc[test_ix])\n",
    "\n",
    "from functools import partial\n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "def log_range(lo, hi): return [10 ** i for i in range(lo, hi)]\n",
    "\n",
    "def sklearn_model_only_metadata(lm, cols, partial, train_tissue_names):\n",
    "    f = list(set(cols.columns) - set(train_tissue_names))\n",
    "    lm.fit(cols[f].iloc[train_ix], partial.iloc[train_ix])\n",
    "    return lm.predict(cols[f].iloc[test_ix])\n",
    "\n",
    "lmmodels = [\n",
    "    ('OLS', linear_model.LinearRegression()),\n",
    "    ('Ridge', linear_model.RidgeCV(alphas=log_range(-1, 4), cv=8)),\n",
    "    ('Lasso', linear_model.LassoCV(alphas=log_range(-6,-1), cv=8)),\n",
    "    ('RFR', ensemble.RandomForestRegressor(n_estimators=100)),\n",
    "    ('ElasticNet', linear_model.ElasticNetCV(l1_ratio=np.arange(.1, 1, .1),\n",
    "                                             alphas=log_range(-5, 5), cv=8)),\n",
    "    #('ARDRegression', linear_model.ARDRegression())\n",
    "]\n",
    "\n",
    "df = train_df_int\n",
    "#df = train_df_imp\n",
    "\n",
    "def run_models(cv_fun):\n",
    "    best = None, [None, None, -np.inf], None\n",
    "    for name, model in lmmodels:\n",
    "        perf = cv_fun(model)\n",
    "        if perf[2] > best[1][2]: best = name, perf\n",
    "        print('\\t{: <16} rmse {:04f} methyl acc {:04f} R^2 {:04f}'.format(name, *perf))\n",
    "    print('\\tBEST', best[0])\n",
    "\n",
    "print('only tissue data')\n",
    "run_models(lambda model: cv_folds(partial(sklearn_model, model), df=df))\n",
    "\n",
    "print('only metadata')\n",
    "run_models(lambda model: cv_folds(partial(sklearn_model_only_metadata, model),\n",
    "                                  df=df, additional_cols=(list(tfs) + ['strand'])))\n",
    "\n",
    "for t in train_tissues:\n",
    "    df[t + 'prev'] = d[t].shift(-1)\n",
    "    df[t + 'next'] = d[t].shift(1)\n",
    "\n",
    "print('only neighbors')\n",
    "nbrs_names = [x + 'prev' for x in train_tissues] + [x + 'next' for x in train_tissues]\n",
    "run_models(lambda model: cv_folds(partial(sklearn_model_only_metadata, model),\n",
    "                                  df=df, additional_cols=nbrs_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "def membased_cf(simil, cols, partial, train_tissue_names):\n",
    "    # https://en.wikipedia.org/wiki/Collaborative_filtering\n",
    "    similarities = np.array([simil(cols[t].iloc[train_ix],\n",
    "                                   partial.iloc[train_ix])\n",
    "                             for t in train_tissue_names])\n",
    "    k = np.sum(np.fabs(similarities))\n",
    "    others = cols[train_tissue_names].iloc[test_ix].values\n",
    "    return others.dot(similarities) / k\n",
    "\n",
    "def cosine_similarity(x, y): return 1 - distance.cosine(x, y)\n",
    "def canberra_similarity(x, y): return len(x) - distance.canberra(x, y)\n",
    "def correlation_similarity(x, y):\n",
    "    c = distance.correlation(x, y)\n",
    "    if np.isnan(c): return 0\n",
    "    else: return 1 - c\n",
    "\n",
    "models = [\n",
    "    ('cosine', cosine_similarity),\n",
    "    ('canberra', canberra_similarity),\n",
    "    ('correlation', correlation_similarity)\n",
    "]\n",
    "print('memory-based aggr CF over different similarities')\n",
    "for name, dist in models:\n",
    "    print(name, perfstr(cv_folds(partial(membased_cf, dist), df=train_df_imp)))\n",
    "\n",
    "# TODO: utilize local values somehow: expand features to neighbors somehow?\n",
    "# TODO: regularized SVD-based CF (need to homebrew with tensorflow)\n",
    "# https://github.com/vlad17/TensorFlow-Learn/blob/master/notebooks/mnist.ipynb for svd, above\n",
    "# TODO: GMM on full tissue samples, then do a marginalized posterior from the limited new\n",
    "# sample data (also needs a homebrew EM). Would use a diagonal, +1, -1 band covar matrix and EM algo.\n",
    "# TODO polynomial multiplication with indicators on the feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ensemble_regression(lm, cols, partial, train_tissue_names, shallow_copy_cols=True):\n",
    "    simil = correlation_similarity\n",
    "    similarities = np.array([simil(cols[t].iloc[train_ix],\n",
    "                                   partial.iloc[train_ix])\n",
    "                             for t in train_tissue_names])\n",
    "    k = np.sum(np.fabs(similarities))\n",
    "    others = cols[train_tissue_names].values\n",
    "    cf = pd.Series(others.dot(similarities) / k, index=cols.index)\n",
    "    if shallow_copy_cols: cols = cols.copy(deep=False)\n",
    "    cols['cf'] = cf\n",
    "    return sklearn_model(lm, cols, partial, train_tissue_names)\n",
    "print('tissue + metadata + CF on interpolation-imputed')\n",
    "run_models(lambda model: cv_folds(partial(ensemble_regression, model),\n",
    "                                  df=df, additional_cols=(list(tfs) + ['strand'] + nbrs_names)))\n",
    "print('tissue + metadata + CF on interpolation-imputed')\n",
    "run_models(lambda model: cv_folds(partial(ensemble_regression, model),\n",
    "                                  df=train_df_int, additional_cols=(list(tfs) + ['strand'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's take a closer look at lm perf for one of our folds.\n",
    "annotations = list(tfs) + ['strand']\n",
    "tissues = train_tissues[:]\n",
    "tissues.remove(closest)\n",
    "\n",
    "lmd = dict(lmmodels)\n",
    "\n",
    "guess_lm_annot = sklearn_model(lmd['ElasticNet'], train_df_imp[annotations],\n",
    "                               train_df_imp[closest], [])\n",
    "guess_lm = sklearn_model(lmd['ElasticNet'], train_df_imp[tissues],\n",
    "                         train_df_imp[closest], tissues)\n",
    "guess_cf = membased_cf(correlation_similarity, train_df_imp[tissues],\n",
    "                       train_df_imp[closest], tissues)\n",
    "\n",
    "exact = train_df_imp[closest].iloc[test_ix]\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print('rmse lm(A)', math.sqrt(mean_squared_error(exact, guess_lm_annot)))\n",
    "print('rmse lm(T)', math.sqrt(mean_squared_error(exact, guess_lm)))\n",
    "print('rmse cf', math.sqrt(mean_squared_error(exact, guess_cf)))\n",
    "\n",
    "res_lma = guess_lm_annot - exact\n",
    "res_lmt = guess_lm - exact\n",
    "res_cf = guess_cf - exact\n",
    "print('lmt, cf corr', scipy.stats.pearsonr(res_lmt, res_cf))\n",
    "print('lma, cf corr', scipy.stats.pearsonr(res_lma, res_cf))\n",
    "print('lma, lmt corr', scipy.stats.pearsonr(res_lma, res_lmt))\n",
    "plt.hist(res_lma, bins=50, alpha=0.7, label='LM(A)')\n",
    "plt.hist(res_cf, bins=50, alpha=0.6, label='CF')\n",
    "plt.hist(res_lmt, bins=50, alpha=0.5, label='LM(T)')\n",
    "plt.xlabel('residual')\n",
    "plt.ylabel('frequency')\n",
    "plt.title('residuals for site-based LM(A) + LM(T) + CF')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "useful_cols = list(train_df_imp.columns)\n",
    "useful_cols.remove('chromosome')\n",
    "useful_cols.remove('start')\n",
    "useful_cols.remove('end')\n",
    "\n",
    "# grid search narrowed down by printing alpha, l1_ratio from CV on training above\n",
    "elastic_net = linear_model.ElasticNetCV(alphas=np.arange(0, 1e-3, 1e-5), cv=10)\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "elastic_net = GridSearchCV(elastic_net, {'l1_ratio': np.arange(.9, 1, .01)})\n",
    "df_with_cf = train_df_int[useful_cols]\n",
    "guess = ensemble_regression(elastic_net, df_with_cf, test_df['filled'],\n",
    "                            train_tissues, shallow_copy_cols=False)\n",
    "exact = test_df['filled'].iloc[test_ix].values\n",
    "\n",
    "rmse = math.sqrt(mean_squared_error(exact, guess))\n",
    "acc = correct_half(exact, guess)\n",
    "r2 = r2_score(exact, guess)\n",
    "res = guess - exact\n",
    "\n",
    "print('Ensemble on test: rmse {:04f} methyl acc {:04f} R^2 {:04f}'.format(rmse, acc, r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(guess - exact, bins=50)\n",
    "plt.xlabel('residual')\n",
    "plt.ylabel('frequency')\n",
    "plt.title('residuals for ensemble')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 2))\n",
    "ratios = []\n",
    "plt.title('rolling mean (n = 1000) methylation levels')\n",
    "plt.xlabel('genomic position')\n",
    "plt.ylabel('mean methyl. prop.')\n",
    "\n",
    "ratios = []\n",
    "\n",
    "x = local_impute(np.copy(test_df['filled']))\n",
    "rolled = pd.Series(x).rolling(window=1000, win_type='boxcar').mean()\n",
    "ratios.append(np.std(x) / np.std(rolled))\n",
    "actual, = plt.plot(rolled, label='exact')\n",
    "\n",
    "def full_ensemble_prediction():\n",
    "    simil = correlation_similarity\n",
    "    cols = df_with_cf\n",
    "    similarities = np.array([simil(cols[t].iloc[train_ix],\n",
    "                                   test_df['filled'].iloc[train_ix])\n",
    "                             for t in train_tissues])\n",
    "    k = np.sum(np.fabs(similarities))\n",
    "    others = cols[train_tissues].values\n",
    "    cf = pd.Series(others.dot(similarities) / k, index=cols.index)\n",
    "    cols = cols.copy(deep=False)\n",
    "    cols['cf'] = cf\n",
    "    return elastic_net.predict(cols)\n",
    "x = full_ensemble_prediction()\n",
    "rolled = pd.Series(x).rolling(window=1000, win_type='boxcar').mean()\n",
    "ratios.append(np.std(x) / np.std(rolled))\n",
    "guess, = plt.plot(rolled, label='regression', alpha=0.7)\n",
    "\n",
    "print('sd ratios', ratios)\n",
    "plt.legend(handles=[actual,guess])\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.isnan(test_df['filled']).sum() / len(test_df), 4.6196193481454584 ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " regularized iterative SVD: for every present user U and some number of factors (dim V)\n",
    " $\\min \\sum_{i,j \\in R} (r_{i,j} - \\mathbf{U}_i \\  \\mathbf{V}_j^T) +  \\lambda (\\sum_i \\lVert \\mathbf{U}_i \\rVert^2   \\sum_j \\lVert \\mathbf{V}_j \\rVert^2)$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
